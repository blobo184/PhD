breaks = c(-Inf, 0.05, 0.1, Inf),
labels = c(1:3)),
Groups2_17 = cut(Result_2017,
breaks = c(-Inf, 0.1, Inf),
labels = c(1:2)))
bes <- left_join(bes, results, by ="pcon")
rm(results)
# Some NAs introduced b/c some false constituencies
bes <- bes %>%
drop_na() ## This drops them, as they will have na for GSSCode
## Append area level variables with gsscode
area_level_vars <- read.csv("Data/Area_level_vars.csv")
bes <- left_join(bes, area_level_vars, by = c("GSSCode" = "ONSConstID"))
rm(area_level_vars)
bes <- bes %>%
mutate(Groups3_17 = case_when(
Groups3_17 == 1 ~ 44,
Groups3_17 == 2 ~ 29,
Groups3_17 == 3 ~ 15))
dat <- foreach(const = unique(bes$GSSCode)) %do% {
temp.dat <- subset(bes, GSSCode == const)
N.target <- temp.dat$Groups3_17[1]
N <- if (nrow(temp.dat) < N.target) {
nrow(temp.dat)} else {N.target}
set.seed(21092020)
dat <- sample_n(temp.dat, N, replace = F, weight = wt)
dat
}
dat <- do.call("rbind", dat)
## Check that majority of required sample sizes are met.
samples <- dat %>%
group_by(GSSCode) %>%
summarise(N = n(),
G = unique(Groups3_17))
round(prop.table(table(samples$N, samples$G),2),4)
## Need to calculate no. of areas in each group
results <- read.csv("Data/Results.csv")
results <- results %>%
dplyr::select(pcon, GSSCode, Result_2017) %>%
mutate(Result_2017 = abs(Result_2017-(1-Result_2017)),
Result_2017 = round(Result_2017,2),
Groups3_17 = cut(Result_2017,
breaks = c(-Inf, 0.05, 0.1, Inf),
labels = c(1:3)),
Groups2_17 = cut(Result_2017,
breaks = c(-Inf, 0.1, Inf),
labels = c(1:2)))
## Percentage each group represents
G1_areas_perc <- sum(results$Groups3_17==1)/ nrow(results)
G2_areas_perc <- sum(results$Groups3_17==2)/ nrow(results)
G3_areas_perc <- sum(results$Groups3_17==3)/ nrow(results)
## Ratio (3:2:1) divided by actual sample perc
G1 <- (3/6) * G1_areas_perc
G2 <- (2/6) * G2_areas_perc
G3 <- (1/6) * G3_areas_perc
group_total <- G1 + G2 + G3
## Groups weighted by sample
G1 <- G1 / group_total
G2 <- G2 / group_total
G3 <- G3 / group_total
## Calculate  sample total
sample <- (632*20)
G1 <- G1*sample
G2 <- G2*sample
G3 <- G3*sample
## Sample per areas
group_3_dist <- c(G1 = round(G1 / sum(results$Groups3_17==1)),
G2 = round(G2 / sum(results$Groups3_17==2)),
G3 = round(G3 / sum(results$Groups3_17==3)))
group_3_dist
## Script to sample from bes full sample
rm(list=ls())
## First source 99_calculate_sample_dist.R
## To calculate sample for groups. Need to set sample size
sample <- (632*20)
source("Code/99_Calculate_sample_dist.R")
group_3_dist
## Script to sample from bes full sample
rm(list=ls())
## First source 99_calculate_sample_dist.R
## To calculate sample for groups. Need to set sample size
sample <- (632*20)
results <- read.csv("Data/Results.csv")
results <- results %>%
dplyr::select(pcon, GSSCode, Result_2017) %>%
mutate(Result_2017 = abs(Result_2017-(1-Result_2017)),
Result_2017 = round(Result_2017,2),
Groups3_17 = cut(Result_2017,
breaks = c(-Inf, 0.05, 0.1, Inf),
labels = c(1:3)),
Groups2_17 = cut(Result_2017,
breaks = c(-Inf, 0.1, Inf),
labels = c(1:2)))
## Percentage each group represents
G1_areas_perc <- sum(results$Groups3_17==1)/ nrow(results)
G2_areas_perc <- sum(results$Groups3_17==2)/ nrow(results)
G3_areas_perc <- sum(results$Groups3_17==3)/ nrow(results)
## Ratio (3:2:1) divided by actual sample perc
G1 <- (3/6) * G1_areas_perc
G2 <- (2/6) * G2_areas_perc
G3 <- (1/6) * G3_areas_perc
group_total <- G1 + G2 + G3
## Groups weighted by sample
G1 <- G1 / group_total
G2 <- G2 / group_total
G3 <- G3 / group_total
## Calculate  sample total
G1 <- G1*sample
G2 <- G2*sample
G3 <- G3*sample
## Sample per areas
group_3_dist <- c(G1 = round(G1 / sum(results$Groups3_17==1)),
G2 = round(G2 / sum(results$Groups3_17==2)),
G3 = round(G3 / sum(results$Groups3_17==3)))
## 2:1 distribution
## Percentage each group represents
G1_areas_perc <- sum(results$Groups2_17==1)/ nrow(results)
G2_areas_perc <- sum(results$Groups2_17==2)/ nrow(results)
## Ratio (3:2:1) divided by actual sample perc
G1 <- (2/3) * G1_areas_perc
G2 <- (1/3) * G2_areas_perc
group_total <- G1 + G2
## Groups weighted by sample
G1 <- G1 / group_total
G2 <- G2 / group_total
## Calculate  sample total
G1 <- G1*sample
G2 <- G2*sample
## Sample per areas
group_2-dist <- c(G1 = round(G1 / sum(results$Groups2_17==1)),
G2 = round(G2 / sum(results$Groups2_17==2)))
round(G1 / sum(results$Groups2_17==1))
round(G2 / sum(results$Groups2_17==2))
## Sample per areas
group_2-dist <- c(G1 = round(G1 / sum(results$Groups2_17==1)),
G2 = round(G2 / sum(results$Groups2_17==2)))
c(G1 = round(G1 / sum(results$Groups2_17==1)),
G2 = round(G2 / sum(results$Groups2_17==2)))
## Sample per areas
group_2_dist <- c(G1 = round(G1 / sum(results$Groups2_17==1)),
G2 = round(G2 / sum(results$Groups2_17==2)))
rm(results, Sample, G1, G1_areas_perc, G2, G2_areas_perc, G3, G3_areas_perc, group_total)
## Script to sample from bes full sample
rm(list=ls())
## First source 99_calculate_sample_dist.R
## To calculate sample for groups. Need to set sample size
sample <- (632*20)
source("Code/99_Calculate_sample_dist.R")
## Create samples for vote choice
load("Data/bes_votechoice_dat.RData")
bes <- bes %>%
dplyr::filter(generalElectionVote != "I would/did not vote")
## Calculate margin of victory for 2017 results and append
## constituency grouping to bes data
results <- read.csv("Data/Results.csv")
results <- results %>%
dplyr::select(pcon, GSSCode, Result_2017) %>%
mutate(Result_2017 = abs(Result_2017-(1-Result_2017)),
Result_2017 = round(Result_2017,2),
Groups3_17 = cut(Result_2017,
breaks = c(-Inf, 0.05, 0.1, Inf),
labels = c(1:3)),
Groups2_17 = cut(Result_2017,
breaks = c(-Inf, 0.1, Inf),
labels = c(1:2)))
bes <- left_join(bes, results, by ="pcon")
rm(results)
# Some NAs introduced b/c some false constituencies
bes <- bes %>%
drop_na() ## This drops them, as they will have na for GSSCode
## Append area level variables with gsscode
area_level_vars <- read.csv("Data/Area_level_vars.csv")
bes <- left_join(bes, area_level_vars, by = c("GSSCode" = "ONSConstID"))
rm(area_level_vars)
bes <- bes %>%
mutate(Groups3_17 = case_when(
Groups3_17 == 1 ~ 44,
Groups3_17 == 2 ~ 29,
Groups3_17 == 3 ~ 15))
dat <- foreach(const = unique(bes$GSSCode)) %do% {
temp.dat <- subset(bes, GSSCode == const)
N.target <- temp.dat$Groups3_17[1]
N <- if (nrow(temp.dat) < N.target) {
nrow(temp.dat)} else {N.target}
set.seed(21092020)
dat <- sample_n(temp.dat, N, replace = F, weight = wt)
dat
}
dat <- do.call("rbind", dat)
## Check that majority of required sample sizes are met.
samples <- dat %>%
group_by(GSSCode) %>%
summarise(N = n(),
G = unique(Groups3_17))
round(prop.table(table(samples$N, samples$G),2),4)
rm(samples)
save(dat, file = "Data/Bes_three.RData")
## Create samples for ratio of 2:1 next
bes <- bes %>%
mutate(Groups2_17 = case_when(
Groups2_17  == 1 ~ 32,
Groups2_17  == 2 ~ 16))
dat <- foreach(const = unique(bes$GSSCode)) %do% {
temp.dat <- subset(bes, GSSCode == const)
N.target <- temp.dat$Groups2_17[1]
N <- if (nrow(temp.dat) < N.target) {
nrow(temp.dat)} else {N.target}
set.seed(21092020)
dat <- sample_n(temp.dat, N, replace = F, weight = wt)
dat
}
dat <- do.call("rbind", dat)
## Check that majority of required sample sizes are met.
samples <- dat %>%
group_by(GSSCode) %>%
summarise(N = n(),
G = unique(Groups2_17))
round(prop.table(table(samples$N, samples$G),2),4)
save(dat, file = "Data/Bes_two.RData")
rm(samples)
## Even sample
dat <- foreach(const = unique(bes$GSSCode)) %do% {
temp.dat <- subset(bes, GSSCode == const)
N <- ifelse(nrow(temp.dat) < 20, nrow(temp.dat), 20)
set.seed(21092020)
dat <- sample_n(temp.dat, N, replace = F, weight = wt)
dat
}
dat <- do.call("rbind", dat)
## Check that majority of required sample sizes are met.
samples <- dat %>%
group_by(GSSCode) %>%
summarise(N = n(),
G = 20)
round(prop.table(table(samples$N, samples$G),2),4)
save(dat, file = "Data/Bes_Even.RData")
load("Data/Bes_Even.RData")
rm(list = ls())
load("Data/Bes_Even.RData")
table(dat$Groups3_17)
75*20
79*20
78*20
632-75-78
479*20
table(dat$pcon)
load("Data/Bes_Two.RData")
table(dat$pcon)
round(prop.table(table(dat$Groups2_17)),2)
load("Data/Bes_Three.RData")
table(dat$pcon)
round(prop.table(table(dat$Groups3_17)),2)
rm(list=ls())
load("Data/Bes_two.RData")
table(dat$pcon)
load("Data/Bes_three.RData")
rm(list=ls())
## poststrat
load("Data/Post_strat.RData")
post_strat <- function(Model){
mod <- if (Model == "Even"){
readRDS("Results/Even.mod.rds")
} else if (Model == "Two") {
readRDS("Results/Two.mod.rds")
} else {readRDS("Results/Three.mod.rds")}
out<- rstanarm::posterior_epred(mod,
newdata=post,
draws = 500)
out.m <- melt(out, varnames = c("iter", "post_row"))
out.m$weight <- post$weight[out.m$post_row]
out.m$GSSCode <- post$GSSCode[out.m$post_row]
out.m$turnout <- post$Turnout[out.m$post_row]
out.m$Con_2019 <- post$Con_2019[out.m$post_row]
results <- out.m %>%
group_by(GSSCode, iter) %>%
summarise(temp.Pred = sum((value*turnout)*weight),
Con_2019 = unique(Con_2019),
err = (temp.Pred - Con_2019))
result.export <- results %>%
group_by(GSSCode) %>%
summarise(Pred = mean(temp.Pred),
Pred_lo = quantile(temp.Pred, 0.05),
Pred_hi = quantile(temp.Pred, 0.95),
MAE.temp = mean(abs(err)),
RMSE.temp = sqrt(mean(err^2)))
if (file.exists("Results/Results_master.xlsx") == "FALSE"){
write.xlsx(result.export, file = "Results/Results_master.xlsx",
append = F,
sheetName = Model)} else {
write.xlsx(result.export, file = "Results/Results_master.xlsx",
append = T,
sheetName = Model)}
Accuracy <- result.export %>%
dplyr::filter(GSSCode != "E14000637") %>% ## exclude speakers seat
summarise(MAE = mean(MAE.temp),
MAE.Low = quantile(MAE.temp,0.05),
MAE.High = quantile(MAE.temp,0.95),
RMSE = mean(RMSE.temp),
RMSE.Low = quantile(RMSE.temp,0.05),
RMSE.High = quantile(RMSE.temp,0.95))
if (file.exists("Results/Accuracy_master.xlsx") == "FALSE"){
write.xlsx(Accuracy, file = "Results/Accuracy_master.xlsx",
append = F,
sheetName = Model)} else {
write.xlsx(Accuracy, file = "Results/Accuracy_master.xlsx",
append = T,
sheetName = Model)}
}
post_strat(Model = "Even")
post_strat(Model = "Two")
post_strat(Model = "Three")
rm(list=ls())
## Script to gather accuracy figures and plot into graph
source("Code/0_Functions.R")
## Gather accuracy
Accuracy <- gather_accuracy(path = "Results/Accuracy_master.xlsx")
## Calculate and append correlation
correl <- get_correl(path = "Results/Results_master.xlsx")
## Combine accuracy and correl
Accuracy <- left_join(Accuracy, correl, by = "Model")
rm(correl)
##  Creat plots and combine into one graph
MAE <- overall.accuracy(measure = "MAE")
RMSE <- overall.accuracy(measure = "RMSE")
Cor <- overall.accuracy(measure = "Cor")
# Combine
Acc_plot <- ggarrange(MAE, RMSE, Cor,
nrow = 1, ncol = 3, common.legend = TRUE, legend = "bottom")
Acc_plot <- annotate_figure(Acc_plot,
top = text_grob("Accuracy of models"))
Acc_plot
ggsave(Acc_plot, file = "Results/Plots/Acc_plots.png") # Save
## Use function to gather MAE and Width for all small areas
## With small area groups appended.
dat <- gather_MAE_and_width(path = "Results/Results_master.xlsx")
## Create table for Even and Three comparison
Three <- dat %>%
dplyr::filter(Model != "Two") %>%
group_by(Groups3_17, Model) %>%
summarise(MAE = mean(MAE.temp),
Width = mean(Width))
## Create table for Two and Even comparison
Two <- dat %>%
dplyr::filter(Model != "Three") %>%
group_by(Groups2_17, Model) %>%
summarise(MAE = mean(MAE.temp),
Width = mean(Width))
## Write out to xlsx sheet in Results folder
write.xlsx(as.data.frame(Three), file = "Results/MAE_&_width.xlsx",
append = F, sheetName = "Three", row.names = F)
write.xlsx(as.data.frame(Two), file = "Results/MAE_&_width.xlsx",
append = T, sheetName = "Two", row.names = F)
View(gather_MAE_and_width)
rm(list=ls())
load("~/Paper 2/Research/External validation/UK/Data/Bes_Even.RData")
table(dat$Groups2_17)
table(dat$Groups3_17)
groups <- dat %>%
dplyr::select(GSSCode, Groups3_17, Groups2_17) %>%
group_by(GSSCode) %>%
summarise(Groups3_17 = unique(Groups3_17),
Groups2_17 = unique(Groups2_17))
groups
## Script to gather accuracy figures and plot into graph
source("Code/0_Functions.R")
## Use function to gather MAE and Width for all small areas
## With small area groups appended.
dat <- gather_MAE_and_width(path = "Results/Results_master.xlsx")
## Create table for Even and Three comparison
Three <- dat %>%
dplyr::filter(Model != "Two") %>%
group_by(Groups3_17, Model) %>%
summarise(MAE = mean(MAE.temp),
Width = mean(Width))
Three
## Create table for Two and Even comparison
Two <- dat %>%
dplyr::filter(Model != "Three") %>%
group_by(Groups2_17, Model) %>%
summarise(MAE = mean(MAE.temp),
Width = mean(Width))
## Write out to xlsx sheet in Results folder
write.xlsx(as.data.frame(Three), file = "Results/MAE_&_width.xlsx",
append = F, sheetName = "Three", row.names = F)
write.xlsx(as.data.frame(Two), file = "Results/MAE_&_width.xlsx",
append = T, sheetName = "Two", row.names = F)
rm(list=ls())
## Load poststrat frame
load("Data/Post_strat.RData")
Brier_reuslts <- function(Model) {
## Load model either Even, Two or Three
mod <- if (Model == "Even"){
readRDS("Results/Even.mod.rds")
} else if (Model == "Two") {
readRDS("Results/Two.mod.rds")
} else {readRDS("Results/Three.mod.rds")}
## Poststrat results with 500 posterior draws
out<- rstanarm::posterior_epred(mod,
newdata=post,
draws = 500)
## Melt out posterior draws by iter
## And append other vars
out.m <- melt(out, varnames = c("iter", "post_row"))
out.m$weight <- post$weight[out.m$post_row]
out.m$GSSCode <- post$GSSCode[out.m$post_row]
out.m$turnout <- post$Turnout[out.m$post_row]
out.m$Con_2019 <- post$Con_2019[out.m$post_row]
## Calculate preds for each iter
results <- out.m %>%
group_by(GSSCode, iter) %>%
summarise(Pred = sum((value*turnout)*weight)) ## Also applying weight
## Read in csv with max vote % for all other parties
## and seat winner
winner <- read.csv("Data/Winner_2019.csv") %>%
rename(GSSCode = ons_id)
## Join with results frame
results <- left_join(winner, results, by = "GSSCode")
## Group by GSSCode and summarise results for final frame
results <- results %>%
dplyr::filter(GSSCode != "E14000637") %>% ## remove spk seat
mutate(Pr_win = ifelse(Pred > Other_max, 1, 0)) %>%
group_by(GSSCode) %>%
summarise(Pr = mean(Pr_win), ## Pr of Con win
Winner = unique(Winner), # Actual winner
Other_max = unique(Other_max), # Max Other vote %
Con_mean = mean(Pred), # Mean Con est.
Con_Hi = quantile(Pred, 0.95), # 95% CI est.
Con_lo = quantile(Pred, 0.05)) %>% # 5$ CI est.
mutate(Winner = ifelse(Winner == "Con", 1, 0),
Br = (Pr - Winner)^2) # Calculate seat breier score
}
Three <- Brier_reuslts("Three")
Two <- Brier_reuslts("Two")
Even <- Brier_reuslts("Even")
## Breir scores
Model_Brier <- left_join(Even, Two, by = "GSSCode") %>%
left_join(., Three, by = "GSSCode") %>%
dplyr::select(GSSCode, Even_Pr = Pr.x, Even_Br = Br.x,
Two_Pr = Pr.y, Two_Br = Br.y,
Three_Pr = Pr, Three_Br = Br) %>%
summarise(Even_seats = sum(Even_Pr),
Even_Br = sum(Even_Br)/631,
Two_seats = sum(Two_Pr),
Two_Br = sum(Two_Br)/631,
Three_seats = sum(Three_Pr),
Three_Br = sum(Three_Br)/631)
Model_Brier
save(Even, Two, Three, Model_Brier, file = "Results/Brier.RData")
## First gather accuracy figures and create one frame
## Script to gather accuracy figures and plot into graph
source("~/Paper 2/Research/External validation/UK/Code/0_Functions.R")
## Gather accuracy
Accuracy <- gather_accuracy(path = "~/Paper 2/Research/External validation/UK/Results/Accuracy_master.xlsx")
## Calculate and append correlation
correl <- get_correl(path = "~/Paper 2/Research/External validation/UK/Results/Results_master.xlsx")
## Combine accuracy and correl
Accuracy <- left_join(Accuracy, correl, by = "Model")
rm(correl)
## Gather estiamtes at small area level
path <- "~/Paper 2/Research/External validation/UK/Results/Results_master.xlsx"
## Gather all estimates for each model (Even, 2:1, 3:2:1)
paths <- path %>%
excel_sheets()
holder <- list()
for (i in 1:3) {
holder[[i]] <- read_excel(path, range = "B1:E633",
col_names = TRUE, sheet = paths[[i]])
holder[[i]]$Model <- paths[[i]]
}
dat <- do.call(rbind, holder) ## Bind into one frame
## Read in and append actual Con 2019 results
results <- read.csv("~/Paper 2/Research/External validation/UK/Data/Results.csv")
results <- results %>%
dplyr::select(GSSCode, Con_2019) # select 2019 Conservative vote sahre
results <- left_join(dat, results, by = "GSSCode")
rm(dat)
## Create accuracy labels
C1 <- paste0("MAE:",round(Accuracy$MAE[1]*100,1),"%",
"\nRMSE:",round(Accuracy$RMSE[1]*100,1), "%",
"\nCor:",round(Accuracy$Cor[1]*100,1), "%")
C2 <- paste0("MAE:",round(Accuracy$MAE[2]*100,1), "%",
"\nRMSE:",round(Accuracy$RMSE[2]*100,1),"%",
"\nCor:",round(Accuracy$Cor[2]*100,1),"%")
C3 <- paste0("MAE:",round(Accuracy$MAE[3]*100,1),"%",
"\nRMSE:",round(Accuracy$RMSE[3]*100,1),"%",
"\nCor:",round(Accuracy$Cor[3]*100,1),"%")
## Save results and accuracy labels to use in Rmarkdown.
save(results, C1, C2, C3, file = "~/Paper 2/Research/External validation/UK/Results/scatter_data.RData")
p1 <- results %>%
dplyr::filter(GSSCode != "E14000637") %>% ## exclude spk seat
mutate(Model = case_when(
Model == "Even" ~ "Even",
Model == "Three" ~ "3:2:1",
Model == "Two" ~ "2:1"))%>%
ggplot(aes(x = Con_2019, y = Pred)) +
geom_point(size = 1, alpha= 4/10) +
geom_errorbar(aes(ymin = Pred_lo, ymax=Pred_hi),
width = 1, alpha = 1/10) +
geom_smooth(method = "lm", color = "red") +
geom_abline(intercept = 0, slope = 1, color = "grey",
linetype = "dashed") +
labs(y="",
x="") +
scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.0,0.55)) +
scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.0,0.55)) +
facet_grid(~Model) +
geom_text(aes(x, y, label= lab),
data = data.frame(x=.15, y = Inf, lab = c(C1, C2, C3),
Model = c("Even", "3:2:1", "2:1")), vjust=1)
p1
ggsave(p1, file= "~/Paper 2/Research/External validation/UK/Results/Plots/Accuracy.png")
rm(list=ls())
